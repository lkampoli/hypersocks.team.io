[
  {
    "objectID": "grants/index.html",
    "href": "grants/index.html",
    "title": "Research Grants",
    "section": "",
    "text": "Research Grants\n\nDog_2019 - 1: Development of tools for determining the definition of optimal EOR: connection of EORand mechanisms of influence, methods of monitoring, 13/03/19 – 16/05/19\nDog_2019 - 2: Development of methods for increasing the predictive ability of three-dimensional digital geological models, 31/05/19 – 30/09/19\nDog_2019 - 3: Development of tools for determining the optimal EOR in terms of the SAW-polymer and alkaline-polymer flooding, estimates of Kohv in a 5-point system work, evaluation of the optimal size of the polymer fringe, 22/10/19 – 31/12/19\nDog_2019 - 4 : Development of methods for increasing the predictive ability of three-dimensional digital geological models, 16/12/19 – 19/03/20\nDog_2019 - 5: Donation agreement No. 117/19-BP, 1/01/20 – 31/12/20\nRSF_RG_2019 - 1: Modeling of non-equilibrium carbon dioxide flows in modern problems of space aerodynamics and ecology of the Earth: 2019 stage 1, 6/05/19 – 31/12/19\nRSF_RG_2019 - 2: Modeling of non-equilibrium flows of carbon dioxide in modern tasks of space aerodynamics and ecology of the Earth: 2020 stage 2, 1/01/20 – 31/12/20\nRSF_RG_2019 - 3: Modeling of non-equilibrium flows of carbon dioxide in modern tasks of space aerodynamics and ecology of the Earth: 2021 stage 3, 1/01/21 – 31/12/21\nM1_2021 - 1: Machine learning in problems of non-equilibrium aeromechanics: 2021 stage 1, 24/08/21 – 31/12/21",
    "crumbs": [
      "Grants"
    ]
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "News",
    "section": "",
    "text": "Acceptance for ON Prime 15 Innovation Program\n\n\n\n\n\nThe Hypersocks Team was successful with the application for ON Prime Program.\n\n\n\n\n\nMar 2024\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "News"
    ]
  },
  {
    "objectID": "research/non-equilibrium_high-speed_flows/index.html",
    "href": "research/non-equilibrium_high-speed_flows/index.html",
    "title": "Non-Equilibrium High-Speed Flows",
    "section": "",
    "text": "Development of a 0/1/2/3D integrated numerical framework for the simulation of non-equilibrium high-speed reactive viscous flows according to a wide range of formulations, from the canonical one- and two-temperature models to multi-temperature and state-to-state implementation."
  },
  {
    "objectID": "research/non-equilibrium_high-speed_flows/index.html#related-publications",
    "href": "research/non-equilibrium_high-speed_flows/index.html#related-publications",
    "title": "Non-Equilibrium High-Speed Flows",
    "section": "Related Publications",
    "text": "Related Publications\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/shock-fitting/index.html",
    "href": "research/shock-fitting/index.html",
    "title": "Shock-Fitting",
    "section": "",
    "text": "Development of shock-fitting techniques for an accurate tracking and representation of flows characterised by the presence of shocks and other discontinuities such that the formal order of accuracy of the underlying CFD solver is preserved."
  },
  {
    "objectID": "research/shock-fitting/index.html#related-publications",
    "href": "research/shock-fitting/index.html#related-publications",
    "title": "Shock-Fitting",
    "section": "Related Publications",
    "text": "Related Publications\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/viscous-fingering/index.html",
    "href": "research/viscous-fingering/index.html",
    "title": "Viscous Fingers",
    "section": "",
    "text": "Numerical Investigation of Viscous Fingering Phenomenon for Raw Field Data."
  },
  {
    "objectID": "research/viscous-fingering/index.html#related-publications",
    "href": "research/viscous-fingering/index.html#related-publications",
    "title": "Viscous Fingers",
    "section": "Related Publications",
    "text": "Related Publications\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "LICENSE",
    "section": "",
    "text": "Adapted from The Turing Way\nOpenscapes makes all of their materials publicly available under open source licenses.\nThe process documents and data are made available under a CC-BY license. Software are made available under an MIT license.\nThe license text listed below (describing both CC-BY and MIT licenses as well as their usage in Openscapes) is re-used under a CC-BY license from The Carpentries community materials. (Specifically from the Reproducible Science Curriculum).\n\n\nAll documentation and chapter materials in this repository are made available under the Creative Commons Attribution license. The following is a human-readable summary of (and not a substitute for) the full legal text of the CC BY 4.0 license.\nYou are free:\n\nto Share—copy and redistribute the material in any medium or format\nto Adapt—remix, transform, and build upon the material\n\nfor any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\n\nAttribution—You must give appropriate credit (mentioning that your work is derived from work that is Copyright © Openscapes and, where practical, linking to https://github.com/openscapes/approach-guide), provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions—You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\nWith the understanding that:\n\nYou do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\nNo warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\n\n\n\n\nExcept where otherwise noted, the software and infrastructure provided by the The Turing Way Community are made available under the OSI-approved MIT license.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "LICENSE.html#process-documents-and-data",
    "href": "LICENSE.html#process-documents-and-data",
    "title": "LICENSE",
    "section": "",
    "text": "All documentation and chapter materials in this repository are made available under the Creative Commons Attribution license. The following is a human-readable summary of (and not a substitute for) the full legal text of the CC BY 4.0 license.\nYou are free:\n\nto Share—copy and redistribute the material in any medium or format\nto Adapt—remix, transform, and build upon the material\n\nfor any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\n\nAttribution—You must give appropriate credit (mentioning that your work is derived from work that is Copyright © Openscapes and, where practical, linking to https://github.com/openscapes/approach-guide), provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions—You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\nWith the understanding that:\n\nYou do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\nNo warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material."
  },
  {
    "objectID": "LICENSE.html#software",
    "href": "LICENSE.html#software",
    "title": "LICENSE",
    "section": "",
    "text": "Except where otherwise noted, the software and infrastructure provided by the The Turing Way Community are made available under the OSI-approved MIT license.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "team/team/lorenzo_campoli/lorenzocampoli.html",
    "href": "team/team/lorenzo_campoli/lorenzocampoli.html",
    "title": "Lorenzo Campoli",
    "section": "",
    "text": "Hello! I’m Lorenzo. I received a Ph.D. degree in Theoretical and Applied Mechanics from Department of Mechanical and Aerospace Engineering from Sapienza University of Rome, Italy in 2016. I was a PostDoc researcher at Saint-Petersburg State University unitl 2022. After that I obtained a professorship from the same University. I’m currently a research fellow at the University of Melbourne and Associate Professor at Macquarie University. My main research interests include:\n\nshock-fitting numerical techniques\nhigh-speed nonequilibrium flows modeling\ndata-driven turbulence model closure\nmachine learning for CFD"
  },
  {
    "objectID": "team/team.html",
    "href": "team/team.html",
    "title": "Hypersocks Team",
    "section": "",
    "text": "Hello! I’m Inna. I’m a Petroleum Systems geologist with 9 years experience in oil and gas upstream sector. Background in petroleum systems and sedimentary basins analysis, petroleum potential assessment, play risk and license blocks evaluation all over the world: Angola, Egypt, Congo (Brazzaville), Gabon, Norway, Mexico, Iran, Kurdistan, Libya. Proficient in petroleum systems modeling: Kurdistan, Pechora sea, Taymyr peninsula, Gydan peninsula, West Siberian basin, Chukotka sea. I’m currently a PhD student at Macquarie University. My main research interests include:\n\nnatural gas exploration\nCO2 capturing\npetroleum system modeling\ngeochemistry\n\nI love dogs, hiking, swimming and reading.",
    "crumbs": [
      "Team"
    ]
  },
  {
    "objectID": "team/team.html#inna-kampoli",
    "href": "team/team.html#inna-kampoli",
    "title": "Hypersocks Team",
    "section": "",
    "text": "Hello! I’m Inna. I’m a Petroleum Systems geologist with 9 years experience in oil and gas upstream sector. Background in petroleum systems and sedimentary basins analysis, petroleum potential assessment, play risk and license blocks evaluation all over the world: Angola, Egypt, Congo (Brazzaville), Gabon, Norway, Mexico, Iran, Kurdistan, Libya. Proficient in petroleum systems modeling: Kurdistan, Pechora sea, Taymyr peninsula, Gydan peninsula, West Siberian basin, Chukotka sea. I’m currently a PhD student at Macquarie University. My main research interests include:\n\nnatural gas exploration\nCO2 capturing\npetroleum system modeling\ngeochemistry\n\nI love dogs, hiking, swimming and reading.",
    "crumbs": [
      "Team"
    ]
  },
  {
    "objectID": "team/team.html#lorenzo-campoli",
    "href": "team/team.html#lorenzo-campoli",
    "title": "Hypersocks Team",
    "section": "Lorenzo Campoli",
    "text": "Lorenzo Campoli\n\n\n\n\n\n\nHello! I’m Lorenzo. I received a Ph.D. degree in Theoretical and Applied Mechanics from Department of Mechanical and Aerospace Engineering from Sapienza University of Rome, Italy in 2016. I was a PostDoc researcher at Saint-Petersburg State University unitl 2022. After that I obtained a professorship from the same University. I’m currently a research fellow at the University of Melbourne and Associate Professor at Macquarie University. My main research interests include:\n\nshock-fitting numerical techniques\nhigh-speed nonequilibrium flows modeling\ndata-driven turbulence model closure\nmachine learning for CFD",
    "crumbs": [
      "Team"
    ]
  },
  {
    "objectID": "codes/index.html",
    "href": "codes/index.html",
    "title": "Hypersocks Team Codes",
    "section": "",
    "text": "See our Github site for relevant group codes:\n\nKAPPA: Kinetic Approach to Physical Processes in Atmospheres This is is an open-source library written in C++ and developed at the Department of Hydroaeromechanics of the Saint Petersburg State University (SPBSU), designed to be coupled with conventional CFD codes to provide thermodynamic, transport, chemistry, and energy transfer properties associated with non-equilibrium reacting flows.\nUnDiFi-2D: an Unstructured Discontinuity Fitting code for 2D grids UnDiFi-2D is written in standard (compliant) Fortran 77/95 with highly modularity as design target. The aim of UnDiFi-2D is to explicitely manage discontinuities in the flow field. In our unstructured shock-fitting approach the shock front is described using a double-sided, polygonal curve. Two sets of flow states, corresponding to the upstream and downstream sides of the discontinuity, are assigned to the grid-points located on either side of the shock front. This is allowed to move, while obeying to the Rankine-Hugoniot jump relations, throughout a background triangular mesh that covers the entire computational domain. At each time step, a local, constrained Delaunay triangulation is applied in the neighbourhood of the shock front to ensure that the edges that make up the shock front are part of the overall triangular grid. The fitted shock acts as an interior boundary for the shock-capturing solver that is used to solve the discretised governing equations in the smooth regions of the flow-field.\nML4STS: Machine Learning for State-To-State This project aims at investigating the usage of machine learning algorithms for Tthe solution of high-speed (viscous and inviscid, reacting and non-reacting) non-equilibrium flows according to a state-to-state (STS) formulation. Several machine learning methods, including neural networks are considered.\nINNA: Introduction to NoNequilibrium Applications This is CFD solver which aims at simulating non-equilibrium flows using different levels of approximations: one-temperature (1T), multi-temperature (MT), state-to-state (STS). The modular design favors the addition of new models or functionalities in a straightforward manner.\nGEP: Gene Expression Programming EVE3 is a machine learning framework based on evolutionary algorithms implemented in Python 3. The framework is mostly used to perform symbolic regression via Gene Expression Programming. EVE3 is capable of regressing multiple mathematical equations simultaneously, scalar, vectorial and tensorial, training the equations towards multiple objectives, using variables of arbitrary dimensionality and evaluating the equations with external software.",
    "crumbs": [
      "Codes"
    ]
  },
  {
    "objectID": "contacts/contacts.html",
    "href": "contacts/contacts.html",
    "title": "Hypersocks Team",
    "section": "",
    "text": "Inna Kampoli\n\n\n{{&lt; fa envelope &gt;}}   inna.kampoli1@hdr.mq.edu.au\n\n\n{{&lt; fa phone &gt;}}   +610452289909\n\n\n{{&lt; fa map-location-dot &gt;}}   Department of Earth and Environmental Sciences Chemistry, Macquarie University, Sydney, NSW, Australia"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "An unsteady shock-fitting technique for unstructured grids\n            \n            \n                \n                \n                    A. Bonfiglioli, R. Paciorri, L. Campoli \n                \n                \n                \n                    \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n            \n\n                    \n                    preprint URL \n                    \n                \n                    \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Unstructured shock-fitting calculations of transonic turbo-machinery flows\n            \n            \n                \n                \n                    A. Bonfiglioli, R. Paciorri, L. Campoli \n                \n                \n                \n                    \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Unsteady shock‐fitting for unstructured grids\n            \n            \n                \n                \n                    Bonfiglioli, A., Paciorri, R., Campoli, L. \n                \n                \n                \n                    \n                        International Journal for Numerical Methods in Fluids, 81, 245-261 (2016)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Development of an unsteady shock-fitting technique for unstructured grids\n            \n            \n                \n                \n                    Bonfiglioli, A., Paciorri, R., Campoli, L., De Amicis, V., Onofri, M. \n                \n                \n                \n                    \n                        Springer, 2, 1501-1504 (2017)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Shock-fitting and predictor-corrector explicit ale residual distribution\n            \n            \n                \n                \n                    Campoli, L., Quemar, P., Bonfiglioli, A., Ricchiuto, M. \n                \n                \n                \n                    \n                        Springer Cham, 1, XVIII, 228 (2017)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Gazpromneft STC Experience in Integration of Structural and Basin Modeling Technologies for Exploration of Petroleum Systems in Regions With Complex Tectonics\n            \n            \n                \n                \n                    Kampoli I., Belenkaya I., Nilov S., Murzin R. \n                \n                \n                \n                    \n                        EAGE, 1, 1-5 (2018)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Overview and perspectives of KAPPA library\n            \n            \n                \n                \n                    Campoli, L., Oblapenko, G. P., Kustova, E. V. \n                \n                \n                \n                    \n                        AIP Conference Proceedings, 1, 2132 (2019)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            KAPPA: Kinetic approach to physical processes in atmospheres library in C++\n            \n            \n                \n                \n                    Campoli, L., Oblapenko, G. P., Kustova , Elena V. \n                \n                \n                \n                    \n                        Computer Physics Communications, 236, 244-267 (2019)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n            \n\n                    \n                    preprint URL \n                    \n                \n                    \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Models validation and code profiling in state-to-state simulations of shock heated air flows\n            \n            \n                \n                \n                    L. Campoli, O. Kunova, E. Kustova, M. Melnik \n                \n                \n                \n                    \n                        Acta Astronautica, 175, 493-509 (2020)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Numerical investigation of viscous fingering phenomenon for raw field data\n            \n            \n                \n                \n                    Bakharev F., Campoli L., Enin A., Matveenko S., Petrova Y., Tikhomirov S., Yakovlev A. \n                \n                \n                \n                    \n                        Transport in Porous Media, 3, 443-464 (2020)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Assessment of Machine Learning Methods for State-to-State Approach in Nonequilibrium Flow Simulations\n            \n            \n                \n                \n                    Campoli, L., Kustova, E., Maltseva, P. \n                \n                \n                \n                    \n                        Mathematics, 10, 928 (2022)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            UnDiFi-2D: an Unstructured Discontinuity Fitting code for 2D grids\n            \n            \n                \n                \n                    Campoli L., Assonitis A., Ciallella M., Paciorri R., Bonfiglioli A., Ricchiuto M. \n                \n                \n                \n                    \n                        Computer Physics Communications, 1, 271 (2022)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n    \n        \n            \n\n                \n                    \n                    \n                    \n\n                \n      \n\n            \n        \n        \n            \n            Distribution, occurrence and identification of dibenzofuran, benzo [b] naphthofurans and their alkyl derivatives in Gippsland Basin source rocks\n            \n            \n                \n                \n                    Jiang L., Nytoft H.P., Kampoli I., George S. C. \n                \n                \n                \n                    \n                        Organic Geochemistry, 187 (2024)\n                        \n                        \n                        \n                        \n                        \n                        \n                \n                    \n                    \n                    \n            \n \n        \n        \n            \n                \n                     \n                \n\n            \n            \n            \n\n                    \n                    journal URL \n                    \n                \n                    \n\n            \n\n        \n    \n    \n    \n    \n\n\nNo matching items",
    "crumbs": [
      "Publications"
    ]
  },
  {
    "objectID": "notebooks/workbook.html",
    "href": "notebooks/workbook.html",
    "title": "<br>\"Hypersocks Team\"",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n!pip install tabulate\nfrom tabulate import tabulate\n\nRequirement already satisfied: tabulate in /home/unimelb.edu.au/lcampoli/miniconda3/lib/python3.8/site-packages (0.8.10)\n\n\n\nfrom IPython.display import display, HTML\ndisplay(HTML(\"&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;\"))\n\n\n\n\n\ndef generate_table(data):\n    headers = [\n        #\"\\\\textbf{N}\", \n        \"\\\\textbf{Data}\", \n        \"\\\\textbf{Name}\", \n        \"\\\\textbf{Company}\", \n        \"\\\\textbf{Role}\", \n        \"\\\\textbf{Segment}\", \n        \"\\\\textbf{Telephone}\",\n        \"\\\\textbf{Email}\", \n        \"\\\\textbf{Linkedin}\", \n        \"\\\\multicolumn{2}{c}{\\\\textbf{Assumption}}\",\n        \"\\\\textbf{Insights}\", \n        \"\\\\textbf{Contacts}\"\n    ]\n\n    rows = []\n    for row in data:\n        date, name, company, role, segment, telephone, email, linkedin, validated_assumptions, invalidated_assumptions, insights, contacts = row\n\n        # Split names\n        name_surname = name.split(\" \")\n        name = \" \\\\\\\\ \".join(name_surname[:len(name_surname)])\n        \n        # Split telephone\n        telephone_lines = telephone.split(\", \")\n        telephone = \" \\\\\\\\ \".join(telephone_lines[:len(telephone_lines)])\n\n        # Split contacts \n        contacts_line = contacts.split(\", \")\n        contacts = \" \\\\\\\\ \".join(contacts_line[:len(contacts_line)])\n            \n        # Split insights\n        insights_line = insights.split(\"; \")\n        insights = \" \\\\\\\\ \".join(insights_line[:len(insights_line)])\n            \n        rows.append([\n            #f\"{num}\",\n            f\"{date}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{name}\\\\end{{tabular}}\",\n            f\"{company}\",\n            f\"{role}\",\n            f\"{segment}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{telephone}\\\\end{{tabular}}\",\n            f\"{email}\",\n            f\"{linkedin}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{validated_assumptions}\\\\end{{tabular}}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{invalidated_assumptions}\\\\end{{tabular}}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{insights}\\\\end{{tabular}}\",\n            f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{contacts}\\\\end{{tabular}} \\\\\\\\\"\n        ])\n\n    table = tabulate(rows, headers, tablefmt=\"latex_raw\", colalign=(\"center\",))\n\n    # Add hline after headers\n    table = table.replace(\"\\\\\\\\\", \"\\\\hline\\n\", 1)\n\n    # Add multirows\n    for i in range(1, len(rows)*3, 3):\n        replace_str = f\" {i} & \"\n        multirow_str = f\" \\\\multirow{{3}}{{*}}{{{i//3+1}}} & \"\n        table = table.replace(replace_str, multirow_str, 1)\n    \n    # Remove the & in front of \\textbf{Data}\n    table = table.replace(\"& \\\\textbf{Data}\", \"\\\\textbf{Data}\", 1)\n    \n    # Add \\\\ after \\textbf{Contacts}\n    table = table.replace(\"\\\\textbf{Contacts}\", \"\\\\textbf{Contacts} \\\\\\\\\", 1)\n    \n    # Replace l with c\n    table = table.replace(\"\\\\begin{tabular}{clllllllllll}\", \"\\\\begin{tabular}{cccccccccccc}\", 1)\n    \n    # Add sidewaystable environment\n    table = \"\\\\begin{sidewaystable}[htbp]\\n\" + table\n    table += \"\\\\caption{HPCs = HPC specialist, SPRS = Senior Principal Research Scientist, PL = Project Leader, SPL = Senior Project Leader, RF = Research Fellow, CE = Chief Executive Officer, EM = Enterprise Manager, GL = Group Leader, DD = Deputy Director, CTO = Chief Technology Officer)}\\\\label{tab:data-structures}\"\n    table += \"\\n\\\\end{sidewaystable}\"\n    \n    # Remove \\hline after \\end{tabular}\n    table = table.replace(\"\\\\end{tabular}\\n\\\\hline\", \"\\\\end{tabular}\")\n    \n    return table\n\n# Example data\ndata = [\n    [   #\"1\",\n        \"19/04/24\",\n        \"Daniel Liang\",\n        \"CSIRO\", # Manufacturing,\n        \"SPRS, SPL\",\n        \"Research Center\",\n        \"0395452981, 0407198957\",\n        \"daniel.liang@csiro.au\",\n        \"\\\\href{https://www.linkedin.com/in/daniel-liang-a97a495a}{linkedin}\",\n        \"\\\\textbf{\\\\textcolor{green}{Validate}}\\\\\\\\ \\\\\\\\ \",\n        \"\\\\textbf{\\\\textcolor{red}{Invalidate}}\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"Lu Yannan, Ritaban Dutta\"\n    ],\n    [   #\"2\",\n        \"19/04/24\",\n        \"Massimiliano Nardini\",\n        \"UniMelb\",\n        \"RF\",\n        \"Univerisity\",\n        \"+393407297092\",\n        \"massimiliano.nardini@unimelb.edu.au\",\n        \"\\\\href{https://www.linkedin.com/in/massimiliano-nardini}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ Coding complexity\\\\\\\\ \",\n        \"N/A\"\n    ],\n    [   #\"3\",\n        \"19/04/24\",\n        \"Melissa Kozul\",\n        \"UniMelb\",\n        \"RF\",\n        \"Univerisity\",\n        \"0421941387\",\n        \"kozulm@unimelb.edu.au\",\n        \"\\\\href{https://www.linkedin.com/in/melissa-kozul-49858827}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ Simulation cost\\\\\\\\ \",\n        \"N/A\"\n    ],\n    [   #\"4\", \n        \"19/04/24\",\n        \"James Stewart\",\n        \"Always Carbon\",\n        \"CEO\",\n        \"Private Company\",\n        \"0401804031\",\n        \"N/A\",\n        \"\\\\href{https://www.linkedin.com/in/james-stewart-a38626}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"Position the software; Plug-in strategy; Purple Cow\",\n        \"N/A\"\n    ],\n    [   #\"5\",\n        \"19/04/24\",\n        \"Peter Kambouris\",\n        \"CSIRO\",\n        \"EM\",\n        \"Research Center\",\n        \"0401804031\",\n        \"peter.kambouris@csiro.au\",\n        \"\\\\href{https://linkedin.com/in/peter-kambouris-99bbb01}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"3x benefit: noted; 10x benefit: competitive; what 'benefit' means; compare with competitors; 3 ppl per Co: CEO/tech/advisor; which resolution for the problem; quality/quantity metrics; read reports\",\n        \"Nick Carter, Mark Cheung\"\n    ],\n    [   #\"6\",\n        \"N/A\",\n        \"Nick Carter\",\n        \"CSIRO\",\n        \"GL\",\n        \"Research Center\",\n        \"0864368614, 0467964895\",\n        \"nick.carter@csiro.au\",\n        \"\\\\href{https://linkedin.com/in/nick-carter-64bb1470}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ],\n    [   #\"7\",\n        \"N/A\",\n        \"Mark Cheung\",\n        \"CSIRO\",\n        \"DD\",\n        \"Research Center\",\n        \"0476870853\",\n        \"mark.cheung@csiro.au\",\n        \"\\\\href{https://linkedin.com/in/mcmcheung}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ],\n    [   #\"8\",\n        \"23/04/24\",\n        \"Joni Sytsma\",\n        \"iLAuNCH\",\n        \"CTO\",\n        \"Government\",\n        \"0499285639\",\n        \"joni.sytsma@outerloop.au\",\n        \"\\\\href{https://linkedin.com/in/joni-sytsma}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"Unique value proposition; product replacement theory; what we got, where we are at, what customers need; CART3D; Ansys; Memko; Leap Australia\",\n        \"Michael Smart\"\n    ],\n    [   #\"9\",\n        \"29/04/24\",\n        \"Andrew Savchenko\",\n        \"Team 3\",\n        \"MD\",\n        \"Private Company\",\n        \"0466955925\",\n        \"andrew@team3.au\",\n        \"\\\\href{https://linkedin.com/in/andrew-savchenko}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ],\n    [   #\"10\",\n        \"26/04/24\",\n        \"Antonio Memmolo\",\n        \"CINECA\",\n        \"HPCs\",\n        \"Research Center\",\n        \"+393202653151\",\n        \"antonio.memmolo@gmail.com\",\n        \"\\\\href{https://linkedin.com/in/antonio-memmolo}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ],\n    [   #\"11\",\n        \"26/04/24\",\n        \"Simone Colonia\",\n        \"Airbus\",\n        \"PL\",\n        \"Research Institute\",\n        \"+447769298326\",\n        \"colonia.simone@gmail.com\",\n        \"\\\\href{https://linkedin.com/in/dr-simone-colonia-314104136}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ],\n    [   #\"12\",\n        \"30/04/24\",\n        \"Stephanie Smith\",\n        \"CSIRO\",\n        \"GL\",\n        \"Research Center\",\n        \"0293724131, 0460017782\",\n        \"stephanie.smith@csiro.au\",\n        \"\\\\href{https://linkedin.com/in/stephanie-smith-b90451a9}{linkedin}\",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\\\\\\\\ \\\\\\\\ \",\n        \"\",\n        \"\"\n    ]\n]\n\n# Generate the table\nlatex_table = generate_table(data)\n\n# Print the LaTeX code\nprint(latex_table)\n\n# Write the LaTeX code to a .tex file\nwith open(\"python2latextable.tex\", \"w\") as f:\n    f.write(latex_table)\n\nprint(\"Table exported to 'python2latextable.tex'\")\n\n# Define column names\ncolumns = ['date', 'name', 'company', 'role', 'segment', 'telephone', 'email', 'linkedin', 'validated assumptions', 'invalidated assumptions', 'insights', 'contacts']\n\n# Create DataFrame with specified column names\ndf = pd.DataFrame(data, columns=columns)\n\n# Count the number of unique segments\nunique_segments = df['segment'].nunique()\nprint(\"Number of segments:\", unique_segments)\n\ndf\n\n\\begin{sidewaystable}[htbp]\n\\begin{tabular}{cccccccccccc}\n\\hline\n          \\textbf{Data}                                                   & \\textbf{Name}   & \\textbf{Company}   & \\textbf{Role}      & \\textbf{Segment}                                                 & \\textbf{Telephone}                  & \\textbf{Email}                                                       & \\textbf{Linkedin}                                                                  & \\multicolumn{2}{c}{\\textbf{Assumption}}                                            & \\textbf{Insights}                                                                                                                                                                                                                                           & \\textbf{Contacts} \\\\                                                     \\hline\n\n\\hline\n 19/04/24 & \\begin{tabular}[c]{@{}c@{}}Daniel \\\\ Liang\\end{tabular}         & CSIRO           & SPRS, SPL          & Research Center    & \\begin{tabular}[c]{@{}c@{}}0395452981 \\\\ 0407198957\\end{tabular} & daniel.liang@csiro.au               & \\href{https://www.linkedin.com/in/daniel-liang-a97a495a}{linkedin}   & \\begin{tabular}[c]{@{}c@{}}\\textbf{\\textcolor{green}{Validate}}\\\\ \\\\ \\end{tabular} & \\begin{tabular}[c]{@{}c@{}}\\textbf{\\textcolor{red}{Invalidate}}\\\\ \\\\ \\end{tabular} & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                                                                                                                                                                                              & \\begin{tabular}[c]{@{}c@{}}Lu Yannan \\\\ Ritaban Dutta\\end{tabular} \\\\ \\\\\n 19/04/24 & \\begin{tabular}[c]{@{}c@{}}Massimiliano \\\\ Nardini\\end{tabular} & UniMelb         & RF                 & Univerisity        & \\begin{tabular}[c]{@{}c@{}}+393407297092\\end{tabular}            & massimiliano.nardini@unimelb.edu.au & \\href{https://www.linkedin.com/in/massimiliano-nardini}{linkedin}    & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ Coding complexity\\\\ \\end{tabular}                                                                                                                                                                                             & \\begin{tabular}[c]{@{}c@{}}N/A\\end{tabular} \\\\                        \\\\\n 19/04/24 & \\begin{tabular}[c]{@{}c@{}}Melissa \\\\ Kozul\\end{tabular}        & UniMelb         & RF                 & Univerisity        & \\begin{tabular}[c]{@{}c@{}}0421941387\\end{tabular}               & kozulm@unimelb.edu.au               & \\href{https://www.linkedin.com/in/melissa-kozul-49858827}{linkedin}  & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ Simulation cost\\\\ \\end{tabular}                                                                                                                                                                                               & \\begin{tabular}[c]{@{}c@{}}N/A\\end{tabular} \\\\                        \\\\\n 19/04/24 & \\begin{tabular}[c]{@{}c@{}}James \\\\ Stewart\\end{tabular}        & Always Carbon   & CEO                & Private Company    & \\begin{tabular}[c]{@{}c@{}}0401804031\\end{tabular}               & N/A                                 & \\href{https://www.linkedin.com/in/james-stewart-a38626}{linkedin}    & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}Position the software \\\\ Plug-in strategy \\\\ Purple Cow\\end{tabular}                                                                                                                                                             & \\begin{tabular}[c]{@{}c@{}}N/A\\end{tabular} \\\\                        \\\\\n 19/04/24 & \\begin{tabular}[c]{@{}c@{}}Peter \\\\ Kambouris\\end{tabular}      & CSIRO           & EM                 & Research Center    & \\begin{tabular}[c]{@{}c@{}}0401804031\\end{tabular}               & peter.kambouris@csiro.au            & \\href{https://linkedin.com/in/peter-kambouris-99bbb01}{linkedin}     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}3x benefit: noted \\\\ 10x benefit: competitive \\\\ what 'benefit' means \\\\ compare with competitors \\\\ 3 ppl per Co: CEO/tech/advisor \\\\ which resolution for the problem \\\\ quality/quantity metrics \\\\ read reports\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Nick Carter \\\\ Mark Cheung\\end{tabular} \\\\ \\\\\n   N/A    & \\begin{tabular}[c]{@{}c@{}}Nick \\\\ Carter\\end{tabular}          & CSIRO           & GL                 & Research Center    & \\begin{tabular}[c]{@{}c@{}}0864368614 \\\\ 0467964895\\end{tabular} & nick.carter@csiro.au                & \\href{https://linkedin.com/in/nick-carter-64bb1470}{linkedin}        & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n   N/A    & \\begin{tabular}[c]{@{}c@{}}Mark \\\\ Cheung\\end{tabular}          & CSIRO           & DD                 & Research Center    & \\begin{tabular}[c]{@{}c@{}}0476870853\\end{tabular}               & mark.cheung@csiro.au                & \\href{https://linkedin.com/in/mcmcheung}{linkedin}                   & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n 23/04/24 & \\begin{tabular}[c]{@{}c@{}}Joni \\\\ Sytsma\\end{tabular}          & iLAuNCH         & CTO                & Government         & \\begin{tabular}[c]{@{}c@{}}0499285639\\end{tabular}               & joni.sytsma@outerloop.au            & \\href{https://linkedin.com/in/joni-sytsma}{linkedin}                 & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}Unique value proposition \\\\ product replacement theory \\\\ what we got, where we are at, what customers need \\\\ CART3D \\\\ Ansys \\\\ Memko \\\\ Leap Australia\\end{tabular}                                                           & \\begin{tabular}[c]{@{}c@{}}Michael Smart\\end{tabular} \\\\              \\\\\n 29/04/24 & \\begin{tabular}[c]{@{}c@{}}Andrew \\\\ Savchenko\\end{tabular}     & Team 3          & MD                 & Private Company    & \\begin{tabular}[c]{@{}c@{}}0466955925\\end{tabular}               & andrew@team3.au                     & \\href{https://linkedin.com/in/andrew-savchenko}{linkedin}            & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n 26/04/24 & \\begin{tabular}[c]{@{}c@{}}Antonio \\\\ Memmolo\\end{tabular}      & CINECA          & HPCs               & Research Center    & \\begin{tabular}[c]{@{}c@{}}+393202653151\\end{tabular}            & antonio.memmolo@gmail.com           & \\href{https://linkedin.com/in/antonio-memmolo}{linkedin}             & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n 26/04/24 & \\begin{tabular}[c]{@{}c@{}}Simone \\\\ Colonia\\end{tabular}       & Airbus          & PL                 & Research Institute & \\begin{tabular}[c]{@{}c@{}}+447769298326\\end{tabular}            & colonia.simone@gmail.com            & \\href{https://linkedin.com/in/dr-simone-colonia-314104136}{linkedin} & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n 30/04/24 & \\begin{tabular}[c]{@{}c@{}}Stephanie \\\\ Smith\\end{tabular}      & CSIRO           & GL                 & Research Center    & \\begin{tabular}[c]{@{}c@{}}0293724131 \\\\ 0460017782\\end{tabular} & stephanie.smith@csiro.au            & \\href{https://linkedin.com/in/stephanie-smith-b90451a9}{linkedin}    & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\\\ \\\\ \\end{tabular}                                     & \\begin{tabular}[c]{@{}c@{}}\\end{tabular}                                                                                                                                                                                                                    & \\begin{tabular}[c]{@{}c@{}}\\end{tabular} \\\\                           \\\\\n\\hline\n\\end{tabular}\\caption{HPCs = HPC specialist, SPRS = Senior Principal Research Scientist, PL = Project Leader, SPL = Senior Project Leader, RF = Research Fellow, CE = Chief Executive Officer, EM = Enterprise Manager, GL = Group Leader, DD = Deputy Director, CTO = Chief Technology Officer)}\\label{tab:data-structures}\n\\end{sidewaystable}\nTable exported to 'python2latextable.tex'\nNumber of segments: 5\n\n\n\n\n\n\n\n\n\n\ndate\nname\ncompany\nrole\nsegment\ntelephone\nemail\nlinkedin\nvalidated assumptions\ninvalidated assumptions\ninsights\ncontacts\n\n\n\n\n0\n19/04/24\nDaniel Liang\nCSIRO\nSPRS, SPL\nResearch Center\n0395452981, 0407198957\ndaniel.liang@csiro.au\n\\href{https://www.linkedin.com/in/daniel-liang...\n\\textbf{\\textcolor{green}{Validate}}\\\\ \\\\\n\\textbf{\\textcolor{red}{Invalidate}}\\\\ \\\\\n\\\\ \\\\\nLu Yannan, Ritaban Dutta\n\n\n1\n19/04/24\nMassimiliano Nardini\nUniMelb\nRF\nUniverisity\n+393407297092\nmassimiliano.nardini@unimelb.edu.au\n\\href{https://www.linkedin.com/in/massimiliano...\n\\\\ \\\\\n\\\\ \\\\\n\\\\ Coding complexity\\\\\nN/A\n\n\n2\n19/04/24\nMelissa Kozul\nUniMelb\nRF\nUniverisity\n0421941387\nkozulm@unimelb.edu.au\n\\href{https://www.linkedin.com/in/melissa-kozu...\n\\\\ \\\\\n\\\\ \\\\\n\\\\ Simulation cost\\\\\nN/A\n\n\n3\n19/04/24\nJames Stewart\nAlways Carbon\nCEO\nPrivate Company\n0401804031\nN/A\n\\href{https://www.linkedin.com/in/james-stewar...\n\\\\ \\\\\n\\\\ \\\\\nPosition the software; Plug-in strategy; Purpl...\nN/A\n\n\n4\n19/04/24\nPeter Kambouris\nCSIRO\nEM\nResearch Center\n0401804031\npeter.kambouris@csiro.au\n\\href{https://linkedin.com/in/peter-kambouris-...\n\\\\ \\\\\n\\\\ \\\\\n3x benefit: noted; 10x benefit: competitive; w...\nNick Carter, Mark Cheung\n\n\n5\nN/A\nNick Carter\nCSIRO\nGL\nResearch Center\n0864368614, 0467964895\nnick.carter@csiro.au\n\\href{https://linkedin.com/in/nick-carter-64bb...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n6\nN/A\nMark Cheung\nCSIRO\nDD\nResearch Center\n0476870853\nmark.cheung@csiro.au\n\\href{https://linkedin.com/in/mcmcheung}{linke...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n7\n23/04/24\nJoni Sytsma\niLAuNCH\nCTO\nGovernment\n0499285639\njoni.sytsma@outerloop.au\n\\href{https://linkedin.com/in/joni-sytsma}{lin...\n\\\\ \\\\\n\\\\ \\\\\nUnique value proposition; product replacement ...\nMichael Smart\n\n\n8\n29/04/24\nAndrew Savchenko\nTeam 3\nMD\nPrivate Company\n0466955925\nandrew@team3.au\n\\href{https://linkedin.com/in/andrew-savchenko...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n9\n26/04/24\nAntonio Memmolo\nCINECA\nHPCs\nResearch Center\n+393202653151\nantonio.memmolo@gmail.com\n\\href{https://linkedin.com/in/antonio-memmolo}...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n10\n26/04/24\nSimone Colonia\nAirbus\nPL\nResearch Institute\n+447769298326\ncolonia.simone@gmail.com\n\\href{https://linkedin.com/in/dr-simone-coloni...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n11\n30/04/24\nStephanie Smith\nCSIRO\nGL\nResearch Center\n0293724131, 0460017782\nstephanie.smith@csiro.au\n\\href{https://linkedin.com/in/stephanie-smith-...\n\\\\ \\\\\n\\\\ \\\\\n\n\n\n\n\n\n\n\n\n\n\n# def generate_table(data):\n#     headers = [\n#         \"\\\\textbf{Data}\", \n#         \"\\\\textbf{Name}\", \n#         \"\\\\textbf{Company}\", \n#         \"\\\\textbf{Role}\", \n#         \"\\\\textbf{Telephone}\",\n#         \"\\\\textbf{Email}\", \n#         \"\\\\textbf{Linkedin}\", \n#         \"\\\\multicolumn{2}{c}{\\\\textbf{Assumption}}\",\n#         \"\\\\textbf{Insights}\", \n#         \"\\\\textbf{Contacts}\"\n#     ]\n\n#     rows = []\n#     for row in data:\n#         date, name, company, role, telephone, email, linkedin, validated_assumptions, invalidated_assumptions, insights, contacts = row\n        \n#         # Split telephone numbers into two lines\n#         telephone_lines = telephone.split(\", \")\n#         if len(telephone_lines) == 2:\n#             telephone = f\"{telephone_lines[0]} \\\\\\\\ {telephone_lines[1]}\"\n            \n#         rows.append([\n#             f\"{date}\",\n#             f\"{name}\",\n#             f\"{company}\",\n#             f\"{role}\",\n#             f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{telephone}\\\\end{{tabular}}\",\n#             f\"{email}\",\n#             f\"{linkedin}\",\n#             f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{validated_assumptions}\\\\end{{tabular}}\",\n#             f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{invalidated_assumptions}\\\\end{{tabular}}\",\n#             f\"\\\\begin{{tabular}}[c]{{@{{}}c@{{}}}}{insights}\\\\end{{tabular}}\",\n#             f\"{contacts} \\\\\\\\\"\n#         ])\n\n#     table = tabulate(rows, headers, tablefmt=\"latex_raw\", colalign=(\"center\",))\n\n#     # Add hline after headers\n#     table = table.replace(\"\\\\\\\\\", \"\\\\hline\\n\", 1)\n\n#     # Add multirows\n#     for i in range(1, len(rows)*3, 3):\n#         replace_str = f\" {i} & \"\n#         multirow_str = f\" \\\\multirow{{3}}{{*}}{{{i//3+1}}} & \"\n#         table = table.replace(replace_str, multirow_str, 1)\n    \n#     # Remove the & in front of \\textbf{Data}\n#     table = table.replace(\"& \\\\textbf{Data}\", \"\\\\textbf{Data}\", 1)\n    \n#     # Add \\\\ after \\textbf{Contacts}\n#     table = table.replace(\"\\\\textbf{Contacts}\", \"\\\\textbf{Contacts} \\\\\\\\\", 1)\n    \n#     # Replace \\begin{tabular}{cllllllllll} with \\begin{tabular}{ccccccccccc}\n#     table = table.replace(\"\\\\begin{tabular}{cllllllllll}\", \"\\\\begin{tabular}{ccccccccccc}\", 1)\n#     table += \"\\\\hline\\n\"\n    \n#     # Add sidewaystable environment\n#     table = \"\\\\begin{sidewaystable}[htbp]\\n\" + table\n#     table += \"\\\\caption{Data Structures (Rotated with Multi-row Header)}\\\\label{tab:data-structures}\"\n#     table += \"\\n\\\\end{sidewaystable}\"\n\n#     # Remove \\hline after \\end{tabular}\n#     table = table.replace(\"\\\\end{tabular}\\n\\\\hline\", \"\\\\end{tabular}\")\n    \n#     # Add legend\n#     #table += \"\\\\multicolumn{11}{l}{{\\\\footnotesize Legend:}} \\\\\\\\\\n\"\n#     #table += \"\\\\multicolumn{11}{l}{{\\\\footnotesize \\\\quad - Yes: Validated Assumption}} \\\n    \n#     return table\n\n# # Example data\n# data = [\n#     [\n#         \"19/04/24\",\n#         \"Daniel Liang\",\n#         \"CSIRO Manufacturing\",\n#         \"Senior Principal Research Scientist, Senior Project Leader\",\n#         \"+61395452981, +61407198957\",\n#         \"daniel.liang@csiro.au\",\n#         \"https://www.linkedin.com/in/daniel-liang-a97a495a/\",\n#         \"\\\\textbf{\\\\textcolor{green}{Validate}}:\\\\\\\\ - Market research\\\\\\\\ - Customer surveys\",\n#         \"\\\\textbf{\\\\textcolor{red}{Invalidate}}:\\\\\\\\ - Competitor analysis\\\\\\\\ - Product testing\",\n#         \"Valuable insights here:\\\\\\\\ - Market trends\\\\\\\\ - Sales projections\",\n#         \"Jane Smith\"\n#     ],\n#     [\n#         \"2024-04-22\",\n#         \"Jane Smith\",\n#         \"XYZ Corp\",\n#         \"Director\",\n#         \"987-654-3210\",\n#         \"janesmith@example.com\",\n#         \"linkedin.com/in/janesmith\",\n#         \"\\\\\\\\ - Product feedback\\\\\\\\ - User interviews\",\n#         \"\\\\\\\\ - Market trends\\\\\\\\ - Competitor analysis\",\n#         \"Interesting findings:\\\\\\\\ - Customer preferences\\\\\\\\ - Product feedback\",\n#         \"John Doe\"\n#     ],\n#     [\n#         \"2024-04-23\",\n#         \"Alice Johnson\",\n#         \"123 Company\",\n#         \"Engineer\",\n#         \"555-123-4567\",\n#         \"alice@example.com\",\n#         \"linkedin.com/in/alicejohnson\",\n#         \"\\\\\\\\ - Product testing\\\\\\\\ - User feedback\",\n#         \"\\\\\\\\ - Market trends\\\\\\\\ - Competitor analysis\",\n#         \"Detailed analysis\",\n#         \"Bob Smith\"\n#     ]\n# ]\n\n# # Generate the table\n# latex_table = generate_table(data)\n\n# # Print the LaTeX code\n# print(latex_table)\n\n# # Write the LaTeX code to a .tex file\n# with open(\"python2latextable.tex\", \"w\") as f:\n#     f.write(latex_table)\n\n# print(\"Table exported to 'python2latextable.tex'\")\n\n\n# from tabulate import tabulate\n\n# def generate_table(data):\n#     headers = [\n#         \"\\\\textbf{Data}\", \"\\\\textbf{Name}\", \"\\\\textbf{Company}\", \"\\\\textbf{Role}\", \"\\\\textbf{Telephone}\",\n#         \"\\\\textbf{Email}\", \"\\\\textbf{Linkedin}\", \"\\\\multicolumn{2}{c}{\\\\textbf{Assumption}}\",\n#         \"\\\\textbf{Insights}\", \"\\\\textbf{Contacts}\"\n#     ]\n\n#     rows = []\n#     for row in data:\n#         date, name, company, role, telephone, email, linkedin, validated_assumptions, invalidated_assumptions, insights, contacts = row\n#         rows.append([\n#             f\"{date}\",\n#             f\"{name}\",\n#             f\"{company}\",\n#             f\"{role}\",\n#             f\"{telephone}\",\n#             f\"{email}\",\n#             f\"{linkedin}\",\n#             f\"\\\\begin{{tabular}}{{ccccccccccc}}{validated_assumptions}\\\\end{{tabular}}\",\n#             f\"\\\\begin{{tabular}}{{ccccccccccc}}{invalidated_assumptions}\\\\end{{tabular}}\",\n#             f\"\\\\begin{{tabular}}{{ccccccccccc}}{insights}\\\\end{{tabular}}\",\n#             f\"{contacts} \\\\\\\\\"\n#         ])\n\n#     table = tabulate(rows, headers, tablefmt=\"latex_raw\", colalign=(\"center\",))\n\n#     # Add hline after headers\n#     table = table.replace(\"\\\\\\\\\", \"\\\\hline\\n\", 1)\n\n#     # Add multirows\n#     for i in range(1, len(rows)*3, 3):\n#         replace_str = f\" {i} & \"\n#         multirow_str = f\" \\\\multirow{{3}}{{*}}{{{i//3+1}}} & \"\n#         table = table.replace(replace_str, multirow_str, 1)\n    \n#     # Remove the & in front of \\textbf{Data}\n#     table = table.replace(\"& \\\\textbf{Data}\", \"\\\\textbf{Data}\", 1)\n    \n#     # Add \\\\ after \\textbf{Contacts}\n#     table = table.replace(\"\\\\textbf{Contacts}\", \"\\\\textbf{Contacts} \\\\\\\\\", 1)\n    \n#     # Replace \\begin{tabular}{cllllllllll} with \\begin{tabular}{ccccccccccc}\n#     table = table.replace(\"\\\\begin{tabular}{cllllllllll}\", \"\\\\begin{tabular}{ccccccccccc}\", 1)\n    \n#     # Add longtable environment\n#     table = \"\\\\begin{longtable}{ccccccccccc}\\n\"\n#     table += \"\\\\caption{Data Structures (Rotated with Multi-row Header)}\\\\label{tab:data-structures}\\\\\\\\\\n\"\n#     table += \"\\\\hline\\n\"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Data}} & \\\\multicolumn{1}{c}{\\\\textbf{Name}} & \\\\multicolumn{1}{c}{\\\\textbf{Company}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Role}} & \\\\multicolumn{1}{c}{\\\\textbf{Telephone}} & \\\\multicolumn{1}{c}{\\\\textbf{Email}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Linkedin}} & \\\\multicolumn{2}{c}{\\\\textbf{Assumption}} & \\\\multicolumn{1}{c}{\\\\textbf{Insights}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Contacts}} \\\\\\\\\\n\"\n#     table += \"\\\\hline\\n\"\n#     table += \"\\\\endfirsthead\\n\"\n#     table += \"\\\\multicolumn{11}{c}{{\\\\tablename\\\\ \\\\thetable{} -- Continued from previous page}} \\\\\\\\\\n\"\n#     table += \"\\\\hline\\n\"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Data}} & \\\\multicolumn{1}{c}{\\\\textbf{Name}} & \\\\multicolumn{1}{c}{\\\\textbf{Company}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Role}} & \\\\multicolumn{1}{c}{\\\\textbf{Telephone}} & \\\\multicolumn{1}{c}{\\\\textbf{Email}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Linkedin}} & \\\\multicolumn{2}{c}{\\\\textbf{Assumption}} & \\\\multicolumn{1}{c}{\\\\textbf{Insights}} & \"\n#     table += \"\\\\multicolumn{1}{c}{\\\\textbf{Contacts}} \\\\\\\\\\n\"\n#     table += \"\\\\hline\\n\"\n#     table += \"\\\\endhead\\n\"\n#     table += \"\\\\hline\\\\multicolumn{11}{r}{{Continued on next page}} \\\\\\\\\\n\"\n#     table += \"\\\\endfoot\\n\"\n#     table += \"\\\\hline\\n\"\n#     table += \"\\\\endlastfoot\\n\"\n#     table += \"\\\\end{longtable}\\n\"\n\n#     return table\n\n# # Example data\n# data = [\n#     [\n#         \"2024-04-21\",\n#         \"John Doe\",\n#         \"ABC Inc.\",\n#         \"Manager\",\n#         \"123-456-7890\",\n#         \"johndoe@example.com\",\n#         \"linkedin.com/in/johndoe\",\n#         \"Yes:\\\\\\\\ - Market research\\\\\\\\ - Customer surveys\",\n#         \"No:\\\\\\\\ - Competitor analysis\\\\\\\\ - Product testing\",\n#         \"Valuable insights here:\\\\\\\\ - Market trends\\\\\\\\ - Sales projections\",\n#         \"Jane Smith\"\n#     ],\n#     [\n#         \"2024-04-22\",\n#         \"Jane Smith\",\n#         \"XYZ Corp\",\n#         \"Director\",\n#         \"987-654-3210\",\n#         \"janesmith@example.com\",\n#         \"linkedin.com/in/janesmith\",\n#         \"No:\\\\\\\\ - Product feedback\\\\\\\\ - User interviews\",\n#         \"Yes:\\\\\\\\ - Market trends\\\\\\\\ - Competitor analysis\",\n#         \"Interesting findings:\\\\\\\\ - Customer preferences\\\\\\\\ - Product feedback\",\n#         \"John Doe\"\n#     ],\n#     [\n#         \"2024-04-23\",\n#         \"Alice Johnson\",\n#         \"123 Company\",\n#         \"Engineer\",\n#         \"555-123-4567\",\n#         \"alice@example.com\",\n#         \"linkedin.com/in/alicejohnson\",\n#         \"Yes:\\\\\\\\ - Product testing\\\\\\\\ - User feedback\",\n#         \"No:\\\\\\\\ - Market trends\\\\\\\\ - Competitor analysis\",\n#         \"Detailed analysis\",\n#         \"Bob Smith\"\n#     ]\n# ]\n\n# # Generate the table\n# latex_table = generate_table(data)\n\n# # Print the LaTeX code\n# print(latex_table)\n\n# # Write the LaTeX code to a .tex file\n# with open(\"output_table.tex\", \"w\") as f:\n#     f.write(latex_table)\n\n# print(\"Table exported to 'output_table.tex'\")\n\n\n# Sample data\n# data = {\n#     'Date': ['2024-04-19', '2024-04-20', '2024-04-21'],\n#     'Name': ['John', 'Alice', 'Bob'],\n#     'Company': ['ABC Inc.', 'XYZ Corp.', 'DEF Co.'],\n#     'Segment': ['Tech', 'Finance', 'Healthcare'],\n#     'Insight': ['New market trends', 'Financial analysis', 'Medical breakthrough'],\n#     'Assumption Validated': [\n#         'Increased demand due to recent tech advancements',\n#         'Growing market in emerging economies',\n#         'Regulatory changes leading to new opportunities'\n#     ],\n#     'Assumption Invalidated': [\n#         'AI adoption in space sector',\n#         'Prioritize fast, accurate and reliable codes',\n#         'Free helpdesk'\n#         ],\n#     'Contacts': [\n#         {'Name': 'Emily', 'Phone': '123-456-7890'},\n#         {'Name': 'David', 'Phone': '987-654-3210'},\n#         {'Name': 'Sarah', 'Phone': '456-789-0123'}\n#     ]\n# }\n\n# # Creating DataFrame\n# df = pd.DataFrame(data)\n\n# # Exporting to Excel\n# file_path = 'data.xlsx'\n# df.to_excel(file_path, index=False)\n\n# print(\"Excel file exported successfully!\")\n\n# # Specify the segment to quantify contacts from\n# specific_segment = 'Tech'\n\n# # Filter DataFrame for the specific segment\n# segment_df = df[df['Segment'] == specific_segment]\n\n# # Calculate total contacts from the specific segment\n# total_contacts = sum(len(contact) for contact in segment_df['Contacts'])\n\n# print(f\"Total contacts from {specific_segment} segment: {total_contacts}\")\n\n\n# import pandas as pd\n\n# # Define the data\n# data = [\n#     {\n#         'Data': '2024-04-21',\n#         'Name': 'John Doe',\n#         'Company': 'ABC Inc.',\n#         'Role': 'Manager',\n#         'Telephone': '123-456-7890',\n#         'Email': 'johndoe@example.com',\n#         'Linkedin': 'linkedin.com/in/johndoe',\n#         'Assumption validated': 'Yes',\n#         'Assumption invalidated': 'No',\n#         'Insights': 'Valuable insights here',\n#         'Contacts': 'Jane Smith'\n#     },\n#     {\n#         'Data': '2024-04-21',\n#         'Name': 'Jane Smith',\n#         'Company': 'XYZ Corp',\n#         'Role': 'Director',\n#         'Telephone': '987-654-3210',\n#         'Email': 'janesmith@example.com',\n#         'Linkedin': 'linkedin.com/in/janesmith',\n#         'Assumption validated': 'No',\n#         'Assumption invalidated': 'Yes',\n#         'Insights': 'Interesting findings',\n#         'Contacts': 'John Doe'\n#     }\n# ]\n\n# # Create a DataFrame\n# df = pd.DataFrame(data)\n\n# # Save to Excel\n# excel_file = \"data.xlsx\"\n# df.to_excel(excel_file, index=False)\n\n# print(\"Data saved to Excel file:\", excel_file)\n\n\n# import pandas as pd\n# #!pip install --upgrade xlsxwriter\n# # Define the updated data\n# data = [\n#     {\n#         'Data': ['2024-04-21', '2024-04-22'],\n#         'Name': ['John Doe', 'Jane Smith'],\n#         'Company': ['ABC Inc.', 'XYZ Corp'],\n#         'Role': ['Manager', 'Director'],\n#         'Telephone': [['123-456-7890'], ['987-654-3210', '555-555-5555']],\n#         'Email': [['johndoe@example.com'], ['janesmith@example.com', 'another@example.com']],\n#         'Linkedin': [['linkedin.com/in/johndoe'], ['linkedin.com/in/janesmith']],\n#         'Assumption validated': [['Yes'], ['No']],\n#         'Assumption invalidated': [['No'], ['Yes']],\n#         'Insights': [['Valuable insights here'], ['Interesting findings']],\n#         'Contacts': [['Jane Smith'], ['John Doe', 'Another Contact']]\n#     }\n# ]\n\n# # Create a DataFrame\n# df = pd.DataFrame(data)\n# df = df.apply(pd.Series.explode)\n\n# # Save to Excel\n# excel_file = \"data_multiple_entries_updated.xlsx\"\n# df.to_excel(excel_file, index=False)\n\n# print(\"Data saved to Excel file:\", excel_file)\n\n\n# import pandas as pd\n\n# # Define the number of data structures to create\n# num_entries = 10\n\n# # Define an empty list to hold the data\n# data = []\n\n# # Loop to create data structures with empty fields\n# for _ in range(num_entries):\n#     entry = {\n#         'Data': [],\n#         'Name': [],\n#         'Company': [],\n#         'Role': [],\n#         'Telephone': [],\n#         'Email': [],\n#         'Linkedin': [],\n#         'Assumption validated': [],\n#         'Assumption invalidated': [],\n#         'Insights': [],\n#         'Contacts': []\n#     }\n#     data.append(entry)\n\n# # Create a DataFrame\n# df = pd.DataFrame(data)\n# df = df.apply(pd.Series.explode)\n\n# # Save to Excel\n# excel_file = \"empty_data_structures.xlsx\"\n# df.to_excel(excel_file, index=False)\n\n# print(\"Empty data structures saved to Excel file:\", excel_file)\n\n\n# import pandas as pd\n\n# # Create a list of dictionaries for the data structure\n# data = [\n#     {\n#         'Data': '2024-04-21',\n#         'Name': 'John Doe',\n#         'Company': 'ABC Inc.',\n#         'Role': 'Manager',\n#         'Telephone': '123-456-7890',\n#         'Email': 'johndoe@example.com',\n#         'Linkedin': 'linkedin.com/in/johndoe',\n#         'Assumption validated': 'Yes',\n#         'Assumption invalidated': 'No',\n#         'Insights': 'Valuable insights here',\n#         'Contacts': 'Jane Smith'\n#     },\n#     {\n#         'Data': '2024-04-22',\n#         'Name': 'Jane Smith',\n#         'Company': 'XYZ Corp',\n#         'Role': 'Director',\n#         'Telephone': '987-654-3210',\n#         'Email': 'janesmith@example.com',\n#         'Linkedin': 'linkedin.com/in/janesmith',\n#         'Assumption validated': 'No',\n#         'Assumption invalidated': 'Yes',\n#         'Insights': 'Interesting findings',\n#         'Contacts': 'John Doe'\n#     },\n#     {\n#         'Data': '2024-04-23',\n#         'Name': 'Alice Johnson',\n#         'Company': '123 Company',\n#         'Role': 'Engineer',\n#         'Telephone': '555-123-4567',\n#         'Email': 'alice@example.com',\n#         'Linkedin': 'linkedin.com/in/alicejohnson',\n#         'Assumption validated': 'Yes',\n#         'Assumption invalidated': 'No',\n#         'Insights': 'Detailed analysis',\n#         'Contacts': 'Bob Smith'\n#     }\n# ]\n\n# # Create a DataFrame (optional)\n# df = pd.DataFrame(data)\n\n# # Save to Excel (optional)\n# excel_file = \"complex_data_structure.xlsx\"\n# df.to_excel(excel_file, index=False)\n\n# print(\"Complex data structure saved to Excel file:\", excel_file)\n\n\nimport matplotlib.pyplot as plt\n#!pip install networkx\nimport networkx as nx\n\n# Create a directed graph\nG = nx.DiGraph()\n\n# Add nodes\nG.add_node(\"Hypersocks Team\")\nG.add_node(\"Node 1\")\nG.add_node(\"Node 2\")\nG.add_node(\"Node 3\")\nG.add_node(\"Node 4\")\nG.add_node(\"Node 5\")\nG.add_node(\"Node 6\")\nG.add_node(\"Node 7\")\n\n# Add edges\nG.add_edge(\"Hypersocks Team\", \"Node 1\")\nG.add_edge(\"Hypersocks Team\", \"Node 2\")\nG.add_edge(\"Hypersocks Team\", \"Node 3\")\nG.add_edge(\"Node 1\", \"Node 4\")\nG.add_edge(\"Node 1\", \"Node 5\")\nG.add_edge(\"Node 2\", \"Node 6\")\n\n# Add edges\nG.add_edge(\"Hypersocks Team\", \"Node 1\")\nG.add_edge(\"Hypersocks Team\", \"Node 2\")\nG.add_edge(\"Hypersocks Team\", \"Node 3\")\nG.add_edge(\"Node 1\", \"Node 4\")\nG.add_edge(\"Node 1\", \"Node 5\")\nG.add_edge(\"Node 3\", \"Node 7\")\n\n# Position nodes using spring layout\npos = nx.spring_layout(G)\n\n# Draw nodes and edges\nnx.draw_networkx_nodes(G, pos, node_size=1000, node_color='lightblue')\nnx.draw_networkx_edges(G, pos, arrows=True)\nnx.draw_networkx_labels(G, pos)\n\n# Display the plot\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n#!pip install graphviz\n#!pip install pygraphviz\n#!pip install viz\n\n\n# import matplotlib.pyplot as plt\n# import networkx as nx\n\n\n# def lanl_graph():\n#     \"\"\"Return the lanl internet view graph from lanl.edges\"\"\"\n#     try:\n#         fh = open(\"lanl_routes.edgelist\")\n#     except OSError:\n#         print(\"lanl.edges not found\")\n#         raise\n\n#     G = nx.Graph()\n\n#     time = {}\n#     time[0] = 0  # assign 0 to center node\n#     for line in fh.readlines():\n#         (head, tail, rtt) = line.split()\n#         G.add_edge(int(head), int(tail))\n#         time[int(head)] = float(rtt)\n\n#     # get largest component and assign ping times to G0time dictionary\n#     Gcc = sorted(nx.connected_components(G), key=len, reverse=True)[0]\n#     G0 = G.subgraph(Gcc)\n#     G0.rtt = {}\n#     for n in G0:\n#         G0.rtt[n] = time[n]\n\n#     return G0\n\n\n# G = lanl_graph()\n\n# print(G)\n# print(nx.number_connected_components(G), \"connected components\")\n\n# plt.figure(figsize=(8, 8))\n# # use graphviz to find radial layout\n# pos = nx.nx_agraph.graphviz_layout(G, prog=\"twopi\", root=0)\n# # draw nodes, coloring by rtt ping time\n# options = {\"with_labels\": False, \"alpha\": 0.5, \"node_size\": 15}\n# nx.draw(G, pos, node_color=[G.rtt[v] for v in G], **options)\n# # adjust the plot limits\n# xmax = 1.02 * max(xx for xx, yy in pos.values())\n# ymax = 1.02 * max(yy for xx, yy in pos.values())\n# plt.xlim(0, xmax)\n# plt.ylim(0, ymax)\n# plt.show()\n\n\n# import matplotlib.pyplot as plt\n# import networkx as nx\n\n\n# def minard_graph():\n#     data1 = \"\"\"\\\n# 24.0,54.9,340000,A,1\n# 24.5,55.0,340000,A,1\n# 25.5,54.5,340000,A,1\n# 26.0,54.7,320000,A,1\n# 27.0,54.8,300000,A,1\n# 28.0,54.9,280000,A,1\n# 28.5,55.0,240000,A,1\n# 29.0,55.1,210000,A,1\n# 30.0,55.2,180000,A,1\n# 30.3,55.3,175000,A,1\n# 32.0,54.8,145000,A,1\n# 33.2,54.9,140000,A,1\n# 34.4,55.5,127100,A,1\n# 35.5,55.4,100000,A,1\n# 36.0,55.5,100000,A,1\n# 37.6,55.8,100000,A,1\n# 37.7,55.7,100000,R,1\n# 37.5,55.7,98000,R,1\n# 37.0,55.0,97000,R,1\n# 36.8,55.0,96000,R,1\n# 35.4,55.3,87000,R,1\n# 34.3,55.2,55000,R,1\n# 33.3,54.8,37000,R,1\n# 32.0,54.6,24000,R,1\n# 30.4,54.4,20000,R,1\n# 29.2,54.3,20000,R,1\n# 28.5,54.2,20000,R,1\n# 28.3,54.3,20000,R,1\n# 27.5,54.5,20000,R,1\n# 26.8,54.3,12000,R,1\n# 26.4,54.4,14000,R,1\n# 25.0,54.4,8000,R,1\n# 24.4,54.4,4000,R,1\n# 24.2,54.4,4000,R,1\n# 24.1,54.4,4000,R,1\"\"\"\n#     data2 = \"\"\"\\\n# 24.0,55.1,60000,A,2\n# 24.5,55.2,60000,A,2\n# 25.5,54.7,60000,A,2\n# 26.6,55.7,40000,A,2\n# 27.4,55.6,33000,A,2\n# 28.7,55.5,33000,R,2\n# 29.2,54.2,30000,R,2\n# 28.5,54.1,30000,R,2\n# 28.3,54.2,28000,R,2\"\"\"\n#     data3 = \"\"\"\\\n# 24.0,55.2,22000,A,3\n# 24.5,55.3,22000,A,3\n# 24.6,55.8,6000,A,3\n# 24.6,55.8,6000,R,3\n# 24.2,54.4,6000,R,3\n# 24.1,54.4,6000,R,3\"\"\"\n#     cities = \"\"\"\\\n# 24.0,55.0,Kowno\n# 25.3,54.7,Wilna\n# 26.4,54.4,Smorgoni\n# 26.8,54.3,Moiodexno\n# 27.7,55.2,Gloubokoe\n# 27.6,53.9,Minsk\n# 28.5,54.3,Studienska\n# 28.7,55.5,Polotzk\n# 29.2,54.4,Bobr\n# 30.2,55.3,Witebsk\n# 30.4,54.5,Orscha\n# 30.4,53.9,Mohilow\n# 32.0,54.8,Smolensk\n# 33.2,54.9,Dorogobouge\n# 34.3,55.2,Wixma\n# 34.4,55.5,Chjat\n# 36.0,55.5,Mojaisk\n# 37.6,55.8,Moscou\n# 36.6,55.3,Tarantino\n# 36.5,55.0,Malo-Jarosewii\"\"\"\n\n#     c = {}\n#     for line in cities.split(\"\\n\"):\n#         x, y, name = line.split(\",\")\n#         c[name] = (float(x), float(y))\n\n#     g = []\n\n#     for data in [data1, data2, data3]:\n#         G = nx.Graph()\n#         i = 0\n#         G.pos = {}  # location\n#         G.pop = {}  # size\n#         last = None\n#         for line in data.split(\"\\n\"):\n#             x, y, p, r, n = line.split(\",\")\n#             G.pos[i] = (float(x), float(y))\n#             G.pop[i] = int(p)\n#             if last is None:\n#                 last = i\n#             else:\n#                 G.add_edge(i, last, **{r: int(n)})\n#                 last = i\n#             i = i + 1\n#         g.append(G)\n\n#     return g, c\n\n\n# (g, city) = minard_graph()\n\n# plt.figure(1, figsize=(11, 5))\n# plt.clf()\n# colors = [\"b\", \"g\", \"r\"]\n# for G in g:\n#     c = colors.pop(0)\n#     node_size = [G.pop[n] // 300 for n in G]\n#     nx.draw_networkx_edges(G, G.pos, edge_color=c, width=4, alpha=0.5)\n#     nx.draw_networkx_nodes(G, G.pos, node_size=node_size, node_color=c, alpha=0.5)\n#     nx.draw_networkx_nodes(G, G.pos, node_size=5, node_color=\"k\")\n\n# for c in city:\n#     x, y = city[c]\n#     plt.text(x, y + 0.1, c)\n# plt.show()\n\n\ndef generate_fortran_subroutine(subroutine_name, arguments, intent=None):\n    \"\"\"\n    Generates a template for a Fortran 2008 subroutine.\n\n    Args:\n        subroutine_name (str): Name of the subroutine.\n        arguments (list of tuples): List of argument names and types.\n                                    Each tuple should be (name, type).\n        intent (list of str, optional): List of intents for arguments.\n                                         Possible values: \"in\", \"out\", \"inout\".\n\n    Returns:\n        str: The generated Fortran subroutine template.\n    \"\"\"\n    template = f\"subroutine {subroutine_name}(\"\n    \n    # Add arguments\n    for arg_name, arg_type in arguments:\n        if intent and arg_name in intent:\n            template += f\"{arg_name}, \"\n        else:\n            template += f\"{arg_name}, \"\n    \n    # Remove the trailing comma and space\n    template = template[:-2] + \")\\n\"\n    \n    # Add argument declarations\n    for arg_name, arg_type in arguments:\n        template += f\"    {arg_type}, intent({intent}) :: {arg_name}\\n\"\n    \n    # Add subroutine body\n    template += \"    ! Add subroutine code here\\n\"\n    \n    template += \"end subroutine\\n\"\n    \n    return template\n\n# Example usage\nsubroutine_name = \"my_subroutine\"\narguments = [(\"arg1\", \"real\"), (\"arg2\", \"integer\")]\nintent = [\"in\", \"out\"]  # Intent for each argument, in the same order as arguments\n\nfortran_code = generate_fortran_subroutine(subroutine_name, arguments, intent)\nprint(fortran_code)\n\nsubroutine my_subroutine(arg1, arg2)\n    real, intent(['in', 'out']) :: arg1\n    integer, intent(['in', 'out']) :: arg2\n    ! Add subroutine code here\nend subroutine\n\n\n\n\ndef generate_fortran_function(function_name, arguments, return_type, description=\"\"):\n    \"\"\"\n    Generates a template for a Fortran 2008 function with Doxygen-style documentation.\n\n    Args:\n        function_name (str): Name of the function.\n        arguments (list of tuples): List of argument names and types.\n                                    Each tuple should be (name, type).\n        return_type (str): Return type of the function.\n        description (str, optional): Description of the function.\n\n    Returns:\n        str: The generated Fortran function template.\n    \"\"\"\n    # Calculate the maximum length of argument names\n    max_arg_length = max(len(arg_name) for arg_name, _ in arguments)\n    \n    # Generate the function header with Doxygen-style comments\n    template = f\"!&gt; {description}\\n\"\n    template += \"!!\\n\"\n    \n    # Generate the function header\n    template += f\"function {function_name}(\"\n    \n    # Add arguments\n    for arg_name, arg_type in arguments:\n        template += f\"{arg_name}, \"\n    \n    # Remove the trailing comma and space\n    template = template[:-2] + \") result(result)\\n\"\n    \n    # Add argument declarations with Doxygen-style comments\n    for arg_name, arg_type in arguments:\n        spaces = \" \" * (max_arg_length - len(arg_name) + 4)  # +4 for \":: \"\n        template += f\"    {arg_type} :: {arg_name}{spaces} !&lt; Description of {arg_name}\\n\"\n    \n    # Add result declaration\n    template += f\"    {return_type} :: result\\n\"\n    \n    # Add function body\n    template += \"    ! Add function code here\\n\"\n    \n    template += \"end function\\n\\n\"\n    \n    return template\n\n\ndef generate_fortran_subroutine(subroutine_name, arguments, intent=None, description=\"\"):\n    \"\"\"\n    Generates a template for a Fortran 2008 subroutine with aligned :: and Doxygen-style documentation.\n\n    Args:\n        subroutine_name (str): Name of the subroutine.\n        arguments (list of tuples): List of argument names and types.\n                                    Each tuple should be (name, type).\n        intent (list of str, optional): List of intents for arguments.\n                                         Possible values: \"in\", \"out\", \"inout\".\n        description (str, optional): Description of the subroutine.\n\n    Returns:\n        str: The generated Fortran subroutine template.\n    \"\"\"\n    # Calculate the maximum length of argument names\n    max_arg_length = max(len(arg_name) for arg_name, _ in arguments)\n    \n    # Generate the subroutine header with Doxygen-style comments\n    template = f\"!&gt; {description}\\n\"\n    template += \"!!\\n\"\n    \n    # Generate the subroutine header\n    template += f\"subroutine {subroutine_name}(\"\n    \n    # Add arguments\n    for arg_name, arg_type in arguments:\n        if intent and arg_name in intent:\n            template += f\"{arg_name}, \"\n        else:\n            template += f\"{arg_name}, \"\n    \n    # Remove the trailing comma and space\n    template = template[:-2] + \")\\n\"\n    \n    # Add argument declarations with Doxygen-style comments\n    for arg_name, arg_type in arguments:\n        spaces = \" \" * (max_arg_length - len(arg_name) + 4)  # +4 for \":: \"\n        template += f\"    {arg_type}, intent({intent}) :: {arg_name}{spaces} !&lt; Description of {arg_name}\\n\"\n    \n    # Add subroutine body\n    template += \"    ! Add subroutine code here\\n\"\n    \n    template += \"end subroutine\\n\\n\"\n    \n    return template\n\n\ndef generate_fortran_module(module_name, subroutines=None, functions=None, description=\"\"):\n    \"\"\"\n    Generates a template for a Fortran 2008 module with Doxygen-style documentation.\n\n    Args:\n        module_name (str): Name of the module.\n        subroutines (list of str, optional): List of subroutine names.\n        functions (list of str, optional): List of function names.\n        description (str, optional): Description of the module.\n\n    Returns:\n        str: The generated Fortran module template.\n    \"\"\"\n    # Generate the module header with Doxygen-style comments\n    template = f\"module {module_name}\\n\"\n    template += f\"!&gt; {description}\\n\"\n    template += \"!!\\n\"\n    \n    # Add subroutines\n    if subroutines:\n        for subroutine in subroutines:\n            template += f\"contains\\n\"\n            template += f\"{subroutine}\\n\\n\"\n    \n    # Add functions\n    if functions:\n        for function in functions:\n            template += f\"{function}\\n\\n\"\n    \n    template += \"end module\\n\\n\"\n    \n    return template\n\n\ndef generate_fortran_program(program_name, uses=None, modules=None, description=\"\"):\n    \"\"\"\n    Generates a template for a Fortran 2008 program with Doxygen-style documentation.\n\n    Args:\n        program_name (str): Name of the program.\n        uses (list of str, optional): List of module names used by the program.\n        modules (list of str, optional): List of module names.\n        description (str, optional): Description of the program.\n\n    Returns:\n        str: The generated Fortran program template.\n    \"\"\"\n    # Generate the program header with Doxygen-style comments\n    template = f\"program {program_name}\\n\"\n    template += f\"!&gt; {description}\\n\"\n    template += \"!!\\n\"\n    \n    # Add \"use\" statements\n    if uses:\n        for module in uses:\n            template += f\"use {module}\\n\"\n    \n    # Add modules\n    if modules:\n        for module in modules:\n            template += f\"use {module}\\n\"\n    \n    template += \"implicit none\\n\\n\"\n    \n    # Add main program body\n    template += \"    ! Add main program code here\\n\"\n    \n    template += \"end program\\n\\n\"\n    \n    return template\n\n\n# Generate functions, subroutines, modules, and main program\nsubroutine_name = \"my_subroutine\"\nsubroutine_description = \"This subroutine does something.\"\narguments = [(\"arg1\", \"real\"), (\"arg2\", \"integer\")]\nintent = [\"in\", \"out\"]  # Intent for each argument, in the same order as arguments\n\nfortran_subroutine = generate_fortran_subroutine(subroutine_name, arguments, intent, subroutine_description)\n\nfunction_name = \"my_function\"\nfunction_description = \"This function calculates something.\"\nreturn_type = \"real\"\nfunction_arguments = [(\"x\", \"real\"), (\"y\", \"real\")]\n\nfortran_function = generate_fortran_function(function_name, function_arguments, return_type, function_description)\n\nmodule_name = \"my_module\"\nmodule_description = \"This module contains subroutines and functions.\"\n\nfortran_module = generate_fortran_module(module_name, subroutines=[fortran_subroutine], functions=[fortran_function], description=module_description)\n\nprogram_name = \"my_program\"\nprogram_description = \"This is the main program.\"\nused_modules = [\"my_module\"]\n\nfortran_program = generate_fortran_program(program_name, uses=used_modules, modules=[module_name], description=program_description)\n\n# Print the generated code\nprint(fortran_subroutine)\nprint(fortran_function)\nprint(fortran_module)\nprint(fortran_program)\n\n!&gt; This subroutine does something.\n!!\nsubroutine my_subroutine(arg1, arg2)\n    real, intent(['in', 'out']) :: arg1     !&lt; Description of arg1\n    integer, intent(['in', 'out']) :: arg2     !&lt; Description of arg2\n    ! Add subroutine code here\nend subroutine\n\n\n!&gt; This function calculates something.\n!!\nfunction my_function(x, y) result(result)\n    real :: x     !&lt; Description of x\n    real :: y     !&lt; Description of y\n    real :: result\n    ! Add function code here\nend function\n\n\nmodule my_module\n!&gt; This module contains subroutines and functions.\n!!\ncontains\n!&gt; This subroutine does something.\n!!\nsubroutine my_subroutine(arg1, arg2)\n    real, intent(['in', 'out']) :: arg1     !&lt; Description of arg1\n    integer, intent(['in', 'out']) :: arg2     !&lt; Description of arg2\n    ! Add subroutine code here\nend subroutine\n\n\n\n!&gt; This function calculates something.\n!!\nfunction my_function(x, y) result(result)\n    real :: x     !&lt; Description of x\n    real :: y     !&lt; Description of y\n    real :: result\n    ! Add function code here\nend function\n\n\n\nend module\n\n\nprogram my_program\n!&gt; This is the main program.\n!!\nuse my_module\nuse my_module\nimplicit none\n\n    ! Add main program code here\nend program"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects Overview",
    "section": "",
    "text": "This section contains a selection of projects of the Hypersocks Team."
  },
  {
    "objectID": "projects/index.html#project-1",
    "href": "projects/index.html#project-1",
    "title": "Projects Overview",
    "section": "Project 1:",
    "text": "Project 1:\n\nPurpose of the projects:\n\n\nHow will the projects be conducted?\n\n\nOutcome"
  },
  {
    "objectID": "projects/index.html#project-2",
    "href": "projects/index.html#project-2",
    "title": "Projects Overview",
    "section": "Project 2:",
    "text": "Project 2:"
  },
  {
    "objectID": "team/team/inna_kampoli/innakampoli.html",
    "href": "team/team/inna_kampoli/innakampoli.html",
    "title": "Inna Kampoli",
    "section": "",
    "text": "Hello! I’m Inna. I’m a Petroleum Systems geologist with 9 years experience in oil and gas upstream sector. Background in petroleum systems and sedimentary basins analysis, petroleum potential assessment, play risk and license blocks evaluation all over the world: Angola, Egypt, Congo (Brazzaville), Gabon, Norway, Mexico, Iran, Kurdistan, Libya. Proficient in petroleum systems modeling: Kurdistan, Pechora sea, Taymyr peninsula, Gydan peninsula, West Siberian basin, Chukotka sea. Currently a PhD student at Macquarie University. I love dogs, hiking, swimming and reading."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Hypersocks Team",
    "section": "",
    "text": "Welcome to the Hypersocks Team webpage!\nThis webpage contains information about the scientific research areas, projects, codes, publications, news and contacts of the Hypersocks Team. It is under active, open development.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "The Hypersocks Team",
    "section": "",
    "text": "Welcome to the Hypersocks Team webpage!\nThis webpage contains information about the scientific research areas, projects, codes, publications, news and contacts of the Hypersocks Team. It is under active, open development.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#about-on-prime",
    "href": "index.html#about-on-prime",
    "title": "The Hypersocks Team",
    "section": "About ON Prime",
    "text": "About ON Prime\n\nON Prime gives researchers the skills and confidence to undertake customer discovery and market validation activities that enable them to take their research further.\nON Prime is a free program designed to help research teams of two to five people take their projects to the next level through customer discovery activities and more. We work with researchers at any stage of their project across all disciplines.\nDuring the nine weeks of ON Prime, you will develop a deeper understanding of the people who could benefit the most from your research and sharpen your skills to communicate with that audience.\nExpert facilitators will support you to build evidence for the impact of your research, so you can make a difference in the world and attract the resources you need along the way.\nLearn more about ON Prime 15 CSIRO Innovation Program at: ON Prime.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "The Hypersocks Team",
    "section": "License",
    "text": "License\nThe Hypersocks Team makes all of their materials publicly available under open source licenses.\nOur License is adapted from The Turing Way",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "research/unsupervised_clustering_in_turbulence_modelling/index.html#related-publications",
    "href": "research/unsupervised_clustering_in_turbulence_modelling/index.html#related-publications",
    "title": "Clustering for turbulence modelling",
    "section": "Related Publications",
    "text": "Related Publications\nDeveloping a transparent and reprodubile pipeline to explore the use of unsupervised clustering algorithms in turbulence modeling."
  },
  {
    "objectID": "research/unsupervised_clustering_in_turbulence_modelling/index.html#related-codes",
    "href": "research/unsupervised_clustering_in_turbulence_modelling/index.html#related-codes",
    "title": "Clustering for turbulence modelling",
    "section": "Related Codes",
    "text": "Related Codes\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research Areas",
    "section": "",
    "text": "Clustering for turbulence modelling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-driven Turbulence Modelling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning for State-to-State\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-Equilibrium High-Speed Flows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShock-Fitting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nViscous Fingers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "research/data-driven_turbulence_modelling/index.html",
    "href": "research/data-driven_turbulence_modelling/index.html",
    "title": "Data-driven Turbulence Modelling",
    "section": "",
    "text": "Data-driven turbulence modeling through Gene Expression Programming evolutionary algorithms to improve RANS predictions by augmenting Reynolds stresses, production terms and turbulent diffusivity fields for several complex geometry testcases."
  },
  {
    "objectID": "research/data-driven_turbulence_modelling/index.html#related-publications",
    "href": "research/data-driven_turbulence_modelling/index.html#related-publications",
    "title": "Data-driven Turbulence Modelling",
    "section": "Related Publications",
    "text": "Related Publications\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "research/machine_learning_for_sts/index.html",
    "href": "research/machine_learning_for_sts/index.html",
    "title": "Machine Learning for State-to-State",
    "section": "",
    "text": "Evaluation of several canonical machine learning algorithms to speed-up state-to-state and multi-temperature kinetic and transport modules."
  },
  {
    "objectID": "research/machine_learning_for_sts/index.html#related-publications",
    "href": "research/machine_learning_for_sts/index.html#related-publications",
    "title": "Machine Learning for State-to-State",
    "section": "Related Publications",
    "text": "Related Publications\n\n\n    \n      \n      \n    \n\n\n    \n    \n\n\nNo matching items"
  }
]